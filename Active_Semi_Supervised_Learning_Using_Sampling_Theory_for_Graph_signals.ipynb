{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "rshpy38",
      "language": "python",
      "name": "rshpy38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Active_Semi-Supervised_Learning_Using_Sampling_Theory_for_Graph_signals.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/broshanfekr/Active_Semi-Supervised_Learning_Using_Sampling_Theory_for_Graph_signals/blob/main/Active_Semi_Supervised_Learning_Using_Sampling_Theory_for_Graph_signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyiwFIOVrWvO"
      },
      "source": [
        "!wget -O USPSdata.zip https://www.dropbox.com/s/f0ktdoudhipohdf/USPSdata.zip?dl=0\n",
        "!unzip USPSdata.zip"
      ],
      "id": "TyiwFIOVrWvO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1515115b"
      },
      "source": [
        "from scipy import spatial\n",
        "from scipy import special\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from numpy.random import permutation\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "from scipy import sparse"
      ],
      "id": "1515115b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff737923"
      },
      "source": [
        "مقداردهی اولیه به برخی از پارامترهای مورد نیاز برای آموزش مدل"
      ],
      "id": "ff737923"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5610b81c"
      },
      "source": [
        "class ArgValus:\n",
        "    def __init__(self):\n",
        "        self.dataset_name = \"USPS\"\n",
        "\n",
        "        # k in knn algorithm\n",
        "        self.k = 10\n",
        "        self.sample_per_class = 100\n",
        "        self.train_percent = 0.01\n",
        "        self.num_iter = 100"
      ],
      "id": "5610b81c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ea495c"
      },
      "source": [
        "لود کردن مجموعه داده مورد نظر و ساخت گراف با استفاده از روش نزدیکترین همسایه"
      ],
      "id": "36ea495c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "235fedd8"
      },
      "source": [
        "def load_dataset(myargs):\n",
        "    img, label = load_USPS_data_instace(\"USPSdata/usps_all.mat\", myargs)\n",
        "    img = np.reshape(img, [img.shape[0], -1])\n",
        "\n",
        "    # building the adjacency matrix\n",
        "    print(\"building adjacency matrix\")\n",
        "    adj_mat, sigma = build_knn_adj_mat(img, k=myargs.k)\n",
        "\n",
        "    return img, label, adj_mat, sigma\n",
        "\n",
        "\n",
        "def load_USPS_data_instace(path, myargs):\n",
        "    data = sio.loadmat(path)\n",
        "    img = data['data']\n",
        "    img_data = []\n",
        "    label = []\n",
        "    for i in range(img.shape[-1]):\n",
        "        temp_sample_list = []\n",
        "        for j in range(img.shape[1]):\n",
        "            temp = np.reshape(img[:, j, i], [16, 16])\n",
        "            temp_sample_list.append(temp)\n",
        "\n",
        "        idx = permutation(len(temp_sample_list))\n",
        "        idx = idx[:myargs.sample_per_class]\n",
        "        selected_samples = [temp_sample_list[x] for x in idx]\n",
        "        selected_labels = [i for _ in idx]\n",
        "        img_data.extend(selected_samples)\n",
        "        label.extend(selected_labels)\n",
        "\n",
        "    img_data = np.array(img_data)\n",
        "    img_data = img_data.astype('float')\n",
        "    label = np.array(label[:])\n",
        "    label = to_onehot(label)\n",
        "    return img_data, label\n",
        "\n",
        "\n",
        "def build_knn_adj_mat(data_nodes, k):\n",
        "    shape = data_nodes.shape\n",
        "    # compute pairwise distances\n",
        "    distance_matrix = np.zeros([shape[0], shape[0]])\n",
        "    # Assign lower triangular part only in loop, saves time\n",
        "    for i in range(shape[0]):\n",
        "        for j in range(i):\n",
        "            distance_matrix[i, j] = spatial.distance.euclidean(data_nodes[i, :],\n",
        "                                                               data_nodes[j, :])\n",
        "    # Complete upper triangular part\n",
        "    distance_matrix = np.add(distance_matrix, distance_matrix.T)\n",
        "\n",
        "    # Calculating distances of k-nearest neighbors\n",
        "    # sort all possible neighbors according to distance\n",
        "    knn_distance = np.sort(distance_matrix, axis=1)\n",
        "\n",
        "    # sparsification matrix\n",
        "    nodes_to_retain = np.ones([shape[0], shape[0]])\n",
        "\n",
        "    for i in range(shape[0]):\n",
        "        nodes_to_retain[i, distance_matrix[i, :] > knn_distance[i, k]] = 0\n",
        "        nodes_to_retain[i, i] = 0  # diagonal should be zero\n",
        "\n",
        "    nodes_to_retain[nodes_to_retain != nodes_to_retain.T] = 1\n",
        "\n",
        "    # keep distances in the range of knn distance\n",
        "    distance_matrix = np.multiply(distance_matrix, nodes_to_retain)\n",
        "\n",
        "    # computing sigma\n",
        "    sigma = 1/3 * np.mean(knn_distance[:, k])\n",
        "\n",
        "    # build knn adjacency matrix\n",
        "    adjacency_mat = np.zeros([shape[0], shape[0]])\n",
        "    for i in range(shape[0]):\n",
        "        for j in range(i):\n",
        "            if distance_matrix[i, j] == 0:\n",
        "                continue\n",
        "            else:\n",
        "                adjacency_mat[i, j] = np.exp((-1.0 * distance_matrix[i, j] ** 2) / (2 * sigma ** 2))\n",
        "    adjacency_mat = adjacency_mat + adjacency_mat.T\n",
        "\n",
        "    return adjacency_mat, sigma\n",
        "\n",
        "\n",
        "def to_onehot(label):\n",
        "    m = len(set(label))\n",
        "    n = len(label)\n",
        "    onehot_matrix = np.zeros([n, m])\n",
        "    for i in range(n):\n",
        "        onehot_matrix[i, label[i]] = 1\n",
        "    return onehot_matrix"
      ],
      "id": "235fedd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ae7e3d5"
      },
      "source": [
        "ساخت ماتریس لاپلاسین نرمال شده با استفاده از ماتریس مجاورت گراف \n",
        "برای ساخت ماتریس لاپلاسین نرمال شده از رابطه زیر استفاده می شود.\n",
        "\n",
        "L = I - D^(-0.5) * A * D^(-0.5)\n",
        "\n",
        "در این رابطه \n",
        "A\n",
        "نشان دهنده ماتریس مجاورت متناظر با گراف است.\n",
        "D\n",
        "نیز نشان دهنده ماتریس درجه مربوط به رئوس گراف است. این ماتریس یک ماتریس قطری است که درایه های قرار گرفته روی قطر اصلی آن درجه رئوس متناظر را نشان می دهند."
      ],
      "id": "8ae7e3d5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91fa3791"
      },
      "source": [
        "def build_normalized_laplacian_matrix(adjacency_matrix):\n",
        "    # compute the symmetric normalized Laplacian matrix\n",
        "    d = np.sum(adjacency_matrix, axis=1, dtype=float)\n",
        "    for i in range(len(d)):\n",
        "        if d[i] != 0:\n",
        "            d[i] = d[i] ** (-1.0/2)\n",
        "    Dinv = np.diag(d)\n",
        "    Ln = np.eye(len(d)) - np.matmul(np.matmul(Dinv, adjacency_matrix), Dinv)\n",
        "    # make sure the Laplacian is symmetric\n",
        "    Ln = 0.5 * (Ln + Ln.T)\n",
        "    return Ln"
      ],
      "id": "91fa3791",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "069b0eef"
      },
      "source": [
        "انتخاب نمونه به منظور انتساب برچسب به آن"
      ],
      "id": "069b0eef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e975382a"
      },
      "source": [
        "def greedy_selection_of_samples(gl, num_of_samples):\n",
        "    #  gl is the graph Laplacian matrix\n",
        "    sample_set = []\n",
        "    omega_list = []\n",
        "    kth_power = 8\n",
        "\n",
        "    Sc = set([i for i in range(gl.shape[0])])\n",
        "\n",
        "    S = np.zeros([gl.shape[0], num_of_samples])\n",
        "\n",
        "    # kth power of Laplacian\n",
        "    print(\"computing proxies\")\n",
        "    L_K = np.linalg.matrix_power(gl, kth_power) \n",
        "    L_K = 0.5 * (L_K + L_K.T)\n",
        "\n",
        "    for i in range(num_of_samples):\n",
        "        print(\"number of selected samples: \", len(sample_set))\n",
        "        rc = sorted(list(Sc))\n",
        "        reduced_L = L_K[rc, :]\n",
        "        reduced_L = reduced_L[:, rc]\n",
        "\n",
        "        eval, evec = eigs(reduced_L, k=1, sigma=10**(-20))\n",
        "\n",
        "        omega = abs(eval) ** (1.0/kth_power)\n",
        "        omega_list.append(omega)\n",
        "\n",
        "        phi = np.absolute(evec)\n",
        "        max_val = max(phi)\n",
        "        max_index = np.argmax(phi)\n",
        "        selected = rc[max_index]\n",
        "        Sc = Sc - {selected}\n",
        "        sample_set.append(selected)\n",
        "\n",
        "    rc = sorted(list(Sc))\n",
        "    reduced_L = L_K[rc, :]\n",
        "    reduced_L = reduced_L[:, rc]\n",
        "    eval, evec = eigs(reduced_L, k=1, sigma=10**(-20))\n",
        "    omega = abs(eval) ** (1.0/kth_power)\n",
        "    omega_list.append(omega)\n",
        "\n",
        "    sample_set = sorted(sample_set)\n",
        "\n",
        "    for i, sidx in enumerate(sample_set):\n",
        "        S[sidx, i] = 1\n",
        "\n",
        "    return S, sample_set, omega"
      ],
      "id": "e975382a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adef521c"
      },
      "source": [
        "بازسازی گراف-سیگنالها با استفاده از گراف-سیگنالهایی که مقادیر آنها در نمونه های انتخاب شده، مشخص گردیده است."
      ],
      "id": "adef521c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2966da6"
      },
      "source": [
        "def reconstruct_signal(Ln, observed_labels, sample_set, omega, myargs):\n",
        "    filterlen = 10\n",
        "    alpha = 8\n",
        "    freq_range = [0, 2]\n",
        "\n",
        "    chebyshev_coef = compute_cheby_coeff(lambda x: special.expit(alpha*(omega - x)), \n",
        "                                         filterlen, filterlen+1, freq_range)\n",
        "    \n",
        "    f_hat = cheby_op(Ln, chebyshev_coef, observed_labels, freq_range)\n",
        "\n",
        "    to_estimate_idx = sorted(list(set(range(Ln.shape[0])) - set(sample_set)))\n",
        "\n",
        "    prev_diffrence = 0\n",
        "    for i in range(myargs.num_iter):\n",
        "        # projection on C1\n",
        "        err_s = observed_labels - f_hat\n",
        "        err_s[to_estimate_idx, :] = 0 # error on the known set\n",
        "\n",
        "        # projection on C2\n",
        "        f_hat_temp = cheby_op(Ln, chebyshev_coef, f_hat + err_s, freq_range) # err on S approx LP\n",
        "\n",
        "        diffrence = np.linalg.norm(f_hat_temp - f_hat) # to check convergence\n",
        "        if i > 1 and diffrence > prev_diffrence:\n",
        "            break\n",
        "        else:\n",
        "            prev_diffrence = diffrence\n",
        "            f_hat = f_hat_temp\n",
        "\n",
        "    return f_hat\n",
        "\n",
        "\n",
        "def compute_cheby_coeff(f, m=30, N=None, a_arange=None):\n",
        "    \"\"\"\n",
        "    Compute Chebyshev coefficients for a Filterbank.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    f : Filter\n",
        "        Filterbank with at least 1 filter\n",
        "    m : int\n",
        "        Maximum order of Chebyshev coeff to compute\n",
        "        (default = 30)\n",
        "    N : int\n",
        "        Grid order used to compute quadrature\n",
        "        (default = m + 1)\n",
        "    i : int\n",
        "        Index of the Filterbank element to compute\n",
        "        (default = 0)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    c : ndarray\n",
        "        Matrix of Chebyshev coefficients\n",
        "\n",
        "    \"\"\"\n",
        "    # G = f.G\n",
        "    # i = kwargs.pop('i', 0)\n",
        "\n",
        "    if not N:\n",
        "        N = m + 1\n",
        "    if not a_arange:\n",
        "        a_arange = [0, 2]\n",
        "\n",
        "    # a_arange = [0, G.lmax]\n",
        "\n",
        "    a1 = (a_arange[1] - a_arange[0]) / 2.0\n",
        "    a2 = (a_arange[1] + a_arange[0]) / 2.0\n",
        "    c = np.zeros(m + 1)\n",
        "\n",
        "    tmpN = np.arange(N)\n",
        "    num = np.cos(np.pi * (tmpN + 0.5) / N)\n",
        "    for o in range(m + 1):\n",
        "        c[o] = 2. / N * np.dot(f(a1 * num + a2),\n",
        "                               np.cos(np.pi * o * (tmpN + 0.5) / N))\n",
        "\n",
        "    return c\n",
        "\n",
        "\n",
        "def cheby_op(L, c, signal, a_arange):\n",
        "    \"\"\"\n",
        "    Chebyshev polynomial of graph Laplacian applied to vector.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    G : Graph\n",
        "    L : Laplacian Matrix of the graph\n",
        "    c : ndarray or list of ndarrays\n",
        "        Chebyshev coefficients for a Filter or a Filterbank\n",
        "    signal : ndarray\n",
        "        Signal to filter\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    r : ndarray\n",
        "        Result of the filtering\n",
        "\n",
        "    \"\"\"\n",
        "    # Handle if we do not have a list of filters but only a simple filter in cheby_coeff.\n",
        "    if not isinstance(c, np.ndarray):\n",
        "        c = np.array(c)\n",
        "\n",
        "    c = np.atleast_2d(c)\n",
        "    Nscales, M = c.shape\n",
        "    N = signal.shape[0]\n",
        "\n",
        "    if M < 2:\n",
        "        raise TypeError(\"The coefficients have an invalid shape\")\n",
        "\n",
        "    # thanks to that, we can also have 1d signal.\n",
        "    try:\n",
        "        Nv = np.shape(signal)[1]\n",
        "        r = np.zeros((N * Nscales, Nv))\n",
        "    except IndexError:\n",
        "        r = np.zeros((N * Nscales))\n",
        "\n",
        "    a1 = float(a_arange[1] - a_arange[0]) / 2.\n",
        "    a2 = float(a_arange[1] + a_arange[0]) / 2.\n",
        "\n",
        "    twf_old = signal\n",
        "    twf_cur = (np.dot(L, signal) - a2 * signal) / a1\n",
        "\n",
        "    tmpN = np.arange(N, dtype=int)\n",
        "    for i in range(Nscales):\n",
        "        r[tmpN + N*i] = 0.5 * c[i, 0] * twf_old + c[i, 1] * twf_cur\n",
        "\n",
        "    factor = 2/a1 * (L - a2 * sparse.eye(N))\n",
        "    for k in range(2, M):\n",
        "        twf_new = factor.dot(twf_cur) - twf_old\n",
        "        for i in range(Nscales):\n",
        "            r[tmpN + N*i] += c[i, k] * twf_new\n",
        "\n",
        "        twf_old = twf_cur\n",
        "        twf_cur = twf_new\n",
        "\n",
        "    return r\n"
      ],
      "id": "d2966da6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e30d7b6"
      },
      "source": [
        "محاسبه دقت دسته بندی"
      ],
      "id": "3e30d7b6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4bbf126"
      },
      "source": [
        "def acc_score(pred_label, true_label, sample_set):\n",
        "    Ind = np.argsort(-np.abs(pred_label), axis=1)\n",
        "    pred_label = Ind[:, 0]\n",
        "\n",
        "    Ind = np.argsort(-np.abs(true_label), axis=1)\n",
        "    true_label = Ind[:, 0]\n",
        "\n",
        "    all_samples = set(range(true_label.shape[0]))\n",
        "    test_idx = list(all_samples - set(sample_set))\n",
        "\n",
        "    test_acc = pred_label[test_idx] == true_label[test_idx]\n",
        "    test_acc = sum(test_acc)/(len(true_label[test_idx]) * 1.0)\n",
        "\n",
        "    train_acc = pred_label[sample_set] == true_label[sample_set]\n",
        "    train_acc = sum(train_acc)/ (len(true_label[sample_set]) * 1.0)\n",
        "\n",
        "    return train_acc, test_acc"
      ],
      "id": "a4bbf126",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7011d644"
      },
      "source": [
        "Active Semi-Supervised Learning Using Sampling Theory for Graph signals"
      ],
      "id": "7011d644"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c730fdbd",
        "outputId": "b0215da5-4cd4-4764-8e8b-7ee61f458025"
      },
      "source": [
        "myargs = ArgValus()\n",
        "\n",
        "img, label, adj_mat_p, sigma = load_dataset(myargs)\n",
        "\n",
        "# compute the symmetric normalized Laplacian matrix\n",
        "Ln = build_normalized_laplacian_matrix(adj_mat_p)\n",
        "\n",
        "# Choosing optimal sampling sets of different sizes\n",
        "print(\"sample selection from Graph...\")\n",
        "S, sample_set, omega = greedy_selection_of_samples(Ln, num_of_samples=round(myargs.train_percent*Ln.shape[0]))\n",
        "\n",
        "# signal reconstruction\n",
        "observed_labels = np.zeros(label.shape)\n",
        "for sample in sample_set:\n",
        "    observed_labels[sample, :] = label[sample, :]\n",
        "f_hat = reconstruct_signal(Ln, observed_labels, sample_set, omega, myargs)\n",
        "\n",
        "train_acc, test_acc = acc_score(f_hat, label, sample_set)\n",
        "print(\"train_acc is: {}    |   test_acc is: {}\".format(train_acc, test_acc))"
      ],
      "id": "c730fdbd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building adjacency matrix\n",
            "sample selection from Graph...\n",
            "computing proxies\n",
            "number of selected samples:  0\n",
            "number of selected samples:  1\n",
            "number of selected samples:  2\n",
            "number of selected samples:  3\n",
            "number of selected samples:  4\n",
            "number of selected samples:  5\n",
            "number of selected samples:  6\n",
            "number of selected samples:  7\n",
            "number of selected samples:  8\n",
            "number of selected samples:  9\n",
            "train_acc is: 1.0    |   test_acc is: 0.5858585858585859\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}